{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "from rcnn_utils import get_object_detection_model, SealDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the GPU if one exists.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using: \", device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_object_detection_model(2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Training Data (150x150 subimages with 25 pixel step)\n",
    "with open(\"../../Data/rcnn_training_data_transformation_True_step_50_sub_image_size_150.pkl\", \"rb\") as f:\n",
    "    training_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_target(img_data, bb_data, threshold=.3):\n",
    "    images = []\n",
    "    targets = []\n",
    "    \n",
    "    for idx in range(len(bb_data)):\n",
    "        \n",
    "        data_frame = bb_data[idx]\n",
    "        sub_image = img_data[idx]\n",
    "\n",
    "        if data_frame is not None:\n",
    "\n",
    "            # Bounding Boxes within a sub-image\n",
    "            boxes = []\n",
    "            labels = []\n",
    "\n",
    "            # Generating target for each bounding box\n",
    "            for i in range(data_frame.shape[0]):\n",
    "\n",
    "                row = data_frame.iloc[i]\n",
    "\n",
    "                # Filter out bad data\n",
    "                if row.xmin < row.xmax: \n",
    "                    \n",
    "                    # Make sure data is above the threshold\n",
    "                    if row.percent >= threshold:\n",
    "                        # YOLO format (x1, y1, x2, y2)\n",
    "                        boxes.append(\n",
    "                            [\n",
    "                                row.xmin,\n",
    "                                row.ymin,\n",
    "                                row.xmax,\n",
    "                                row.ymax,\n",
    "                            ]\n",
    "                        )\n",
    "                        labels.append(1)\n",
    "\n",
    "            # Create targets\n",
    "            if len(boxes) > 0:\n",
    "                targets.append(\n",
    "                    {\n",
    "                        \"boxes\": torch.tensor(boxes),\n",
    "                        \"labels\": torch.tensor(labels)\n",
    "                    }\n",
    "                )\n",
    "                images.append(sub_image)\n",
    "\n",
    "    return images, targets\n",
    "\n",
    "def get_all_data(data_dictionary):\n",
    "    total_images = []\n",
    "    total_targets = []\n",
    "    image_names = data_dictionary.keys()\n",
    "\n",
    "    for file_name in tqdm(image_names):\n",
    "\n",
    "        # Get sub-images and bounding box data\n",
    "        image, bb = data_dictionary[file_name]\n",
    "\n",
    "        # Generate targets (bounding box format for RCNN)\n",
    "        images, targets = get_images_target(image, bb)\n",
    "\n",
    "        total_images += images\n",
    "        total_targets += targets\n",
    "\n",
    "    return total_images, total_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images, training_targets = get_all_data(training_data)\n",
    "print(f\"Sub-images used for training: {len(training_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    To handle the data loading as different images may have different number \n",
    "    of objects and to handle varying size tensors as well.\n",
    "    \"\"\"\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unbatch(batch, device):\n",
    "    \"\"\"\n",
    "    Unbatches a batch of data from the Dataloader.\n",
    "    Inputs\n",
    "        batch: tuple\n",
    "            Tuple containing a batch from the Dataloader.\n",
    "        device: str\n",
    "            Indicates which device (CPU/GPU) to use.\n",
    "    Returns\n",
    "        X: list\n",
    "            List of images.\n",
    "        y: list\n",
    "            List of dictionaries.\n",
    "    \"\"\"\n",
    "    X, y = batch\n",
    "    X = [x.to(device) for x in X]\n",
    "    y = [{k: v.to(device) for k, v in t.items()} for t in y]\n",
    "    return X, y\n",
    "\n",
    "def train_batch(batch, model, optimizer, device):\n",
    "    \"\"\"\n",
    "    Uses back propagation to train a model.\n",
    "    Inputs\n",
    "        batch: tuple\n",
    "            Tuple containing a batch from the Dataloader.\n",
    "        model: torch model\n",
    "        optimizer: torch optimizer\n",
    "        device: str\n",
    "            Indicates which device (CPU/GPU) to use.\n",
    "    Returns\n",
    "        loss: float\n",
    "            Sum of the batch losses.\n",
    "        losses: dict\n",
    "            Dictionary containing the individual losses.\n",
    "    \"\"\"\n",
    "    X, y = unbatch(batch, device = device)    \n",
    "    optimizer.zero_grad()\n",
    "    losses = model(X, y)\n",
    "    loss = sum(loss for loss in losses.values())\n",
    "    loss.backward()\n",
    "    optimizer.step()    \n",
    "    return loss, losses\n",
    "\n",
    "def train_epoch(epoch, model, optimizer, train_loader, device=\"cpu\"):\n",
    "    prog_bar = tqdm(total= len(train_loader))\n",
    "    mae = 0\n",
    "    total = 0\n",
    "    update_cycle = 1\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        loss, losses = train_batch(batch, model, optimizer, device)\n",
    "        mae += abs(loss.item())\n",
    "        total += 1\n",
    "        if total % update_cycle == 0:\n",
    "            prog_bar.update(update_cycle)\n",
    "            prog_bar.set_description(\"Epoch: {} MAE: {}\".format(epoch, round(mae/total, 4)))\n",
    "            prog_bar.refresh()\n",
    "    return mae / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rcnn(rcnn, epochs, train_loader, write_path=None, model_name=\"\", label=\"\", saved_checkpoints=None, device=device):\n",
    "\n",
    "    rcnn.train()\n",
    "    \n",
    "    # Returnables\n",
    "    training_mae = []\n",
    "\n",
    "    # RCNN Set up\n",
    "    params = [p for p in rcnn.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr = .005, momentum = 0.9, weight_decay = 0.0005)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    # Begin Training\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        epoch_mae = train_epoch(epoch, rcnn, optimizer, train_loader, device)\n",
    "\n",
    "        # Saw best results without scheduler\n",
    "        # lr_scheduler.step()\n",
    "\n",
    "        training_mae.append(epoch_mae)\n",
    "\n",
    "        # Save Checkpoint\n",
    "        if write_path is not None and saved_checkpoints is not None:\n",
    "            if epoch in saved_checkpoints:\n",
    "                torch.save(\n",
    "                    rcnn.state_dict(),\n",
    "                    f\"{write_path}/rcnn_{model_name}_{label}_{epoch}\"\n",
    "                )\n",
    "\n",
    "    # Save Final Model\n",
    "    if write_path is not None :\n",
    "        torch.save(\n",
    "            rcnn.state_dict(),\n",
    "            f\"{write_path}/rcnn_{model_name}_{label}_{epoch}\"\n",
    "        )\n",
    "\n",
    "    return training_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = SealDataset(training_images, training_targets)\n",
    "train_loader = DataLoader(dataset = train_data, shuffle=True, collate_fn=collate_fn, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 50\n",
    "checkpoints_epochs = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "write_path = \"../Models\"\n",
    "model_name = \"resnet_v2_unfrozen\"\n",
    "label = \"transformations_step_50_no_lr_scheduler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = train_rcnn(model, epoch_num, train_loader, write_path, model_name, label, checkpoints_epochs, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
