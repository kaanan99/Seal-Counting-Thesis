{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_predictor_dataframe_directory = \"Score Predictor DataFrames\"\n",
    "\n",
    "if score_predictor_dataframe_directory not in os.listdir():\n",
    "    os.mkdir(score_predictor_dataframe_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_value = 300\n",
    "nms_threshold = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"unfrozen\", \"frozen_v1\", \"frozen_v2\"]\n",
    "dataset_types = [\"training\", \"validation\", \"testing\"]\n",
    "\n",
    "csv_path =\"Grid Search DataFrames\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models:\n",
    "    print(\"Generating Dataframe for model:\", model_name)\n",
    "\n",
    "    for dataset_type in dataset_types:\n",
    "        print(\"Using dataset:\", dataset_type)\n",
    "\n",
    "        # Read in Data\n",
    "        cluster_df = pd.read_csv(f\"{csv_path}\\centriod_info_{model_name}_{dataset_type}.csv\")\n",
    "        scores_df = pd.read_csv(f\"{csv_path}\\grid_search_{model_name}_{dataset_type}.csv\")\n",
    "\n",
    "        # Filter out to specified NMS threshold and DBSCAN search radius\n",
    "        cluster_df = cluster_df[cluster_df[\"Epsilon Value\"] == epsilon_value]\n",
    "        scores_df = scores_df[scores_df[\"IOU Threshold\"] == nms_threshold]\n",
    "\n",
    "        merge_columns = [\"File Name\", \"Count Difference\"]\n",
    "\n",
    "        # Calcualte minimum difference from actual score\n",
    "        minimum_differences =(\n",
    "            scores_df\n",
    "            .groupby(\"File Name\")\n",
    "            .min()\n",
    "            .reset_index()\n",
    "            [merge_columns]\n",
    "        )\n",
    "\n",
    "        # Filter score df to only have best scores\n",
    "        scores_df = (\n",
    "            scores_df\n",
    "            .merge(\n",
    "                minimum_differences, \n",
    "                how=\"inner\", \n",
    "                right_on=merge_columns, \n",
    "                left_on=merge_columns\n",
    "            )\n",
    "            .drop(columns=[\"Unnamed: 0\"])\n",
    "        )\n",
    "\n",
    "        # Combine cluster and score data\n",
    "        score_predictor_df = (\n",
    "            scores_df\n",
    "            .merge(\n",
    "                cluster_df, \n",
    "                left_on=\"File Name\", \n",
    "                right_on= \"Image Name\"\n",
    "            )\n",
    "            .drop(\n",
    "                columns=[\n",
    "                    \"Image Name\", \n",
    "                    \"IOU Threshold\", \n",
    "                    \"Epsilon Value\"\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Save to csv\n",
    "\n",
    "        # Raw Data\n",
    "        score_predictor_df.to_csv(f\"{score_predictor_dataframe_directory}/{model_name}_{dataset_type}_ep_{epsilon_value}_nms_{nms_threshold}_raw.csv\", index=False)\n",
    "\n",
    "        # Aggregated to have min score\n",
    "        score_predictor_df.loc[score_predictor_df.groupby(\"File Name\")[\"Score\"].idxmin()].to_csv(f\"{score_predictor_dataframe_directory}/{model_name}_{dataset_type}_ep_{epsilon_value}_nms_{nms_threshold}_min.csv\", index=False)\n",
    "        \n",
    "        # Aggregated to have max score\n",
    "        score_predictor_df.loc[score_predictor_df.groupby(\"File Name\")[\"Score\"].idxmax()].to_csv(f\"{score_predictor_dataframe_directory}/{model_name}_{dataset_type}_ep_{epsilon_value}_nms_{nms_threshold}_max.csv\", index=False)\n",
    "        \n",
    "        # Aggregated to have average score\n",
    "        score_predictor_df.groupby(\"File Name\").mean().reset_index().to_csv(f\"{score_predictor_dataframe_directory}/{model_name}_{dataset_type}_ep_{epsilon_value}_nms_{nms_threshold}_mean.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
