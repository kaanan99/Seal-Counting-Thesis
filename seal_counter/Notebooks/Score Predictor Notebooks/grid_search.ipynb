{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "from torchvision import ops\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\\RCNN Notebooks\")\n",
    "from rcnn_utils import decode_prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score and NMS Treshold Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb(in_path, xml):\n",
    "   df = pd.DataFrame()\n",
    "   i = 0\n",
    "   for x in xml:\n",
    "      f = open(in_path + x)\n",
    "      xml_file = bs(\"\".join(f.readlines()), \"lxml\")\n",
    "      df_temp = parse_xml(xml_file)\n",
    "      df_temp.insert(0, \"file_num\", str(i).zfill(4))\n",
    "      df = pd.concat([df, df_temp])\n",
    "      f.close()\n",
    "      i+=1\n",
    "   return df\n",
    "\n",
    "def parse_xml(xml):\n",
    "  label = xml.find_all(\"name\")\n",
    "  xmin = xml.find_all(\"xmin\")\n",
    "  ymin = xml.find_all(\"ymin\")\n",
    "  xmax = xml.find_all(\"xmax\")\n",
    "  ymax = xml.find_all(\"ymax\")\n",
    "  min_size = min(len(label), len(xmin), len(ymin), len(xmax), len(ymax))\n",
    "  for i in range(min_size):\n",
    "      label[i] = label[i].text\n",
    "      xmin[i] = xmin[i].text\n",
    "      ymin[i] = ymin[i].text\n",
    "      xmax[i] = xmax[i].text\n",
    "      ymax[i] = ymax[i].text\n",
    "  df = pd.DataFrame({\"label\": label[:min_size], \"xmin\": xmin[:min_size], \"ymin\": ymin[:min_size], \"xmax\": xmax[:min_size], \"ymax\": ymax[:min_size]})\n",
    "  return df\n",
    "\n",
    "def get_actual_count(path, file_name):\n",
    "  xml_name = file_name + \".xml\"\n",
    "  return get_bb(path, [xml_name]).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_score_results(image_predictions, nms_threshold, actual_count):\n",
    "    score_values = []\n",
    "    count_predictions = []\n",
    "    count_differences = []\n",
    "\n",
    "    potential_scores = [round(x, 2) for x in np.arange(0.0, 1.0, 0.05)]\n",
    "    for score in potential_scores:\n",
    "        predicted_count = 0\n",
    "        for prediction in image_predictions:\n",
    "            boxes, scores, labels = decode_prediction(prediction, score, nms_threshold)\n",
    "            predicted_count += len(boxes)\n",
    "\n",
    "        # Update Values\n",
    "        score_values.append(score)\n",
    "        count_predictions.append(predicted_count)\n",
    "        count_differences.append(abs(actual_count - predicted_count))\n",
    "        \n",
    "    return score_values, count_predictions, count_differences\n",
    "\n",
    "def conduct_grid_search(dataset_predictions, dataset_image_path, write_path=None, name=\"\"):\n",
    "    # Initialize dict to store df information\n",
    "    data_frame_dict = {\n",
    "        \"File Name\": [], \n",
    "        \"Score\": [], \n",
    "        \"IOU Threshold\": [], \n",
    "        \"Predicted Counts\": [], \n",
    "        \"Actual Count\": [], \n",
    "        \"Count Difference\": []\n",
    "    }\n",
    "\n",
    "    nms_thresholds = [round(x, 2) for x in np.arange(0.0, 1.0, 0.05)]\n",
    "\n",
    "    for image_name in tqdm(dataset_predictions.keys()):\n",
    "        # Initialize image variables\n",
    "        actual_image_counts = get_actual_count(dataset_image_path, image_name)\n",
    "        image_predictions = dataset_predictions[image_name]\n",
    "\n",
    "        for nms_thresh in nms_thresholds:\n",
    "\n",
    "            # Calculate predicted count of all score for an image\n",
    "            score_values, count_predictions, count_differences = get_image_score_results(image_predictions, nms_thresh, actual_image_counts)\n",
    "            num_observations = len(score_values)\n",
    "            \n",
    "            # Update values in dataframe\n",
    "            data_frame_dict[\"File Name\"] += [image_name] * num_observations\n",
    "            data_frame_dict[\"Score\"] += score_values\n",
    "            data_frame_dict[\"IOU Threshold\"] += [nms_thresh] * num_observations\n",
    "            data_frame_dict[\"Predicted Counts\"] += count_predictions\n",
    "            data_frame_dict[\"Actual Count\"] += [actual_image_counts] * num_observations\n",
    "            data_frame_dict[\"Count Difference\"] += count_differences\n",
    "    \n",
    "    grid_search_df = pd.DataFrame(data_frame_dict)\n",
    "\n",
    "    # Save CSV\n",
    "    if write_path is not None:\n",
    "        if name != \"\":\n",
    "            name = \"_\"+name\n",
    "        grid_search_df.to_csv(\"{}/grid_search{}.csv\".format(write_path, name))\n",
    "    \n",
    "    return grid_search_df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grid_search(preds, path, write_path = None, name = \"\"):\n",
    "    scores_arr_total = []\n",
    "    pred_counts_total = []\n",
    "    count_diffs_total = []\n",
    "    file_names_total = []\n",
    "    thresh_arr_total = []\n",
    "    actual_counts_total = []\n",
    "\n",
    "    iou_thresh = [round(x, 2) for x in np.arange(0.0, 1.0, 0.05)]\n",
    "    for file_name in tqdm(preds.keys()):\n",
    "        actual_count = get_actual_count(path, file_name)\n",
    "        for thresh in iou_thresh:\n",
    "            file_names, scores_arr, thresh_arr, pred_counts, actual_counts, count_diffs = get_scores(preds, thresh, file_name, actual_count)\n",
    "            scores_arr_total += scores_arr\n",
    "            pred_counts_total += pred_counts\n",
    "            count_diffs_total += count_diffs\n",
    "            file_names_total += file_names\n",
    "            thresh_arr_total += thresh_arr\n",
    "            actual_counts_total += actual_counts\n",
    "\n",
    "    df = pd.DataFrame({\"File Name\": file_names_total, \"Score\":scores_arr_total, \"IOU Threshold\": thresh_arr_total, \"Predicted Counts\": pred_counts_total, \"Actual Count\": actual_counts_total, \"Count Difference\": count_diffs_total})\n",
    "    \n",
    "    if write_path is not None:\n",
    "        if name != \"\":\n",
    "            name = \"_\"+name\n",
    "        df.to_csv(\"{}/grid_search{}.csv\".format(write_path, name), index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"unfrozen\", \"frozen_v1\", \"frozen_v2\"]\n",
    "dataset_image_paths = {\n",
    "    \"training\": \"Training Images\",\n",
    "    \"validation\": \"Validation Images\",\n",
    "    \"testing\": \"Test Images\"\n",
    "}\n",
    "dataset_types = list(dataset_image_paths.keys())\n",
    "write_path = r\"..\\MetaData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Predictions for: unfrozen\n",
      "\tUsing dataset: training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:12<01:14,  1.86s/it]C:\\Users\\kaanan\\AppData\\Roaming\\Python\\Python310\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 58%|█████▊    | 29/50 [00:38<00:12,  1.67it/s]C:\\Users\\kaanan\\AppData\\Roaming\\Python\\Python310\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "100%|██████████| 50/50 [00:58<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing dataset: validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:29<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing dataset: testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:09<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Predictions for: frozen_v1\n",
      "\tUsing dataset: training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:14<01:25,  2.13s/it]C:\\Users\\kaanan\\AppData\\Roaming\\Python\\Python310\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 58%|█████▊    | 29/50 [00:43<00:14,  1.45it/s]C:\\Users\\kaanan\\AppData\\Roaming\\Python\\Python310\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "100%|██████████| 50/50 [01:08<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing dataset: validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:34<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing dataset: testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:11<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Predictions for: frozen_v2\n",
      "\tUsing dataset: training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:15<01:36,  2.42s/it]C:\\Users\\kaanan\\AppData\\Roaming\\Python\\Python310\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 58%|█████▊    | 29/50 [00:49<00:16,  1.30it/s]C:\\Users\\kaanan\\AppData\\Roaming\\Python\\Python310\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "100%|██████████| 50/50 [01:16<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing dataset: validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:37<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing dataset: testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:12<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    print(\"Generating Predictions for:\", model_name)\n",
    "    for dataset_type in dataset_types:\n",
    "        print(\"\\tUsing dataset:\", dataset_type)\n",
    "        write_name = f\"{model_name}_{dataset_type}\"\n",
    "\n",
    "        dataset_image_path = r\"C:\\Users\\kaanan\\Desktop\\Training, Val, and Test Images\\{}/\".format(dataset_image_paths[dataset_type])\n",
    "        \n",
    "        dataset_path = r\"..\\MetaData\\{}_{}_predictions.pkl\".format(model_name, dataset_type)\n",
    "        with open(dataset_path, \"rb\") as fp:\n",
    "            rcnn_predictions = pickle.load(fp)\n",
    "        \n",
    "        grid_search_df = conduct_grid_search(rcnn_predictions, dataset_image_path, write_path, write_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_centriod_metrics(image_centriods, eps):\n",
    "    if len(image_centriods) > 0:\n",
    "        \n",
    "        clustering_object = DBSCAN(eps=eps, min_samples=1).fit(image_centriods)\n",
    "        labels = pd.Series(clustering_object.labels_)\n",
    "\n",
    "        # Filter out invalid clusters\n",
    "        valid_cluster_indices = labels > -1\n",
    "        labels = labels[valid_cluster_indices].value_counts()\n",
    "\n",
    "        seal_sub_image_number = labels.sum()\n",
    "        cluster_number = len(labels)\n",
    "\n",
    "        largest_cluster = labels.max()\n",
    "        smallest_cluster = labels.min()\n",
    "\n",
    "        return seal_sub_image_number, cluster_number, largest_cluster, smallest_cluster\n",
    "   \n",
    "    else:\n",
    "        return 0, 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_centriod_grid_search(centriods, write_path=None, write_name=None):\n",
    "    data_frame_dict = {\n",
    "        \"Image Name\": [],\n",
    "        \"Epsilon Value\": [],\n",
    "        \"Sub-Images with Seals\": [],\n",
    "        \"Number of Clusters\": [],\n",
    "        \"Largest Cluster Size\": [],\n",
    "        \"Smallest Cluster Size\": [],\n",
    "    }\n",
    "\n",
    "    epsilon_values = [150, 300, 450]   \n",
    "\n",
    "    for image_name in tqdm(centriods.keys()):\n",
    "        image_centriods = centriods[image_name]\n",
    "        \n",
    "        for epsilon_value in epsilon_values:\n",
    "            seal_sub_image_number, cluster_number, largest_cluster, smallest_cluster = calculate_centriod_metrics(image_centriods, epsilon_value)\n",
    "\n",
    "            data_frame_dict[\"Image Name\"].append(image_name)\n",
    "            data_frame_dict[\"Epsilon Value\"].append(epsilon_value)\n",
    "            data_frame_dict[ \"Sub-Images with Seals\"].append(seal_sub_image_number)\n",
    "            data_frame_dict[\"Number of Clusters\"].append(cluster_number)\n",
    "            data_frame_dict[\"Largest Cluster Size\"].append(largest_cluster)\n",
    "            data_frame_dict[\"Smallest Cluster Size\"].append(smallest_cluster)\\\n",
    "            \n",
    "    centriod_info_df = pd.DataFrame(data_frame_dict)\n",
    "\n",
    "    if write_path is not None:\n",
    "        if write_name is not None:\n",
    "            centriod_info_df.to_csv(f\"{write_path}/centriod_info_{write_name}.csv\", index=False)\n",
    "        else:\n",
    "            centriod_info_df.to_csv(f\"{write_path}/centriod_info.csv\", index=False)\n",
    "\n",
    "    return centriod_info_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Grid Search for model: unfrozen\n",
      "\tUsing Dataset: training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 84.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing Dataset: validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 134.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing Dataset: testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 85.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Grid Search for model: frozen_v1\n",
      "\tUsing Dataset: training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 88.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing Dataset: validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 122.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing Dataset: testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 95.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Grid Search for model: frozen_v2\n",
      "\tUsing Dataset: training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 87.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing Dataset: validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 138.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing Dataset: testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 99.48it/s]\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    print(\"Generating Grid Search for model:\", model_name)\n",
    "    for dataset_type in dataset_types:\n",
    "        print(\"\\tUsing Dataset:\", dataset_type)\n",
    "\n",
    "        write_name = f\"{model_name}_{dataset_type}\"\n",
    "\n",
    "        centriods_path = r\"..\\MetaData\\seals_centroids_{}.pkl\".format(dataset_type)\n",
    "        with open(centriods_path, \"rb\") as fp:\n",
    "                    centriods = pickle.load(fp)\n",
    "        \n",
    "        conduct_centriod_grid_search(centriods, write_path, write_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
