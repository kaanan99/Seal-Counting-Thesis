{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supporting Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from torchvision import ops\n",
    "\n",
    "# Models\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\\RCNN Notebooks\")\n",
    "from rcnn_utils import decode_prediction, write_to_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"unfrozen\"\n",
    "epsilon_value = 300\n",
    "nms_threshold = 0.2\n",
    "data_reduction_type = \"mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_prediction_path = r\"..\\MetaData\\{}_{}_predictions.pkl\".format(model_name, \"training\")\n",
    "validation_prediction_path = r\"..\\MetaData\\{}_{}_predictions.pkl\".format(model_name, \"validation\")\n",
    "testing_prediction_path = r\"..\\MetaData\\{}_{}_predictions.pkl\".format(model_name, \"testing\")\n",
    "\n",
    "with open(training_prediction_path, \"rb\") as fp:\n",
    "    training_predictions = pickle.load(fp)\n",
    "with open(validation_prediction_path, \"rb\") as fp:\n",
    "    validation_predictions = pickle.load(fp)\n",
    "with open(testing_prediction_path, \"rb\") as fp:\n",
    "    testing_predictions = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv(r\"score_predictor_data_frames\\{}_training_ep_{}_nms_{}_{}.csv\".format(model_name, epsilon_value, nms_threshold, data_reduction_type))\n",
    "validation_df = pd.read_csv(r\"score_predictor_data_frames\\{}_validation_ep_{}_nms_{}_{}.csv\".format(model_name, epsilon_value, nms_threshold, data_reduction_type))\n",
    "testing_df = pd.read_csv(r\"score_predictor_data_frames\\{}_testing_ep_{}_nms_{}_{}.csv\".format(model_name, epsilon_value, nms_threshold, data_reduction_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['Sub-Images with Seals', 'Number of Clusters','Largest Cluster Size', 'Smallest Cluster Size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df\n",
    "y_train = training_df[\"Score\"]\n",
    "x_train = training_df[input_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "linear_regression = LinearRegression()\n",
    "random_forest = RandomForestRegressor(random_state=0)\n",
    "\n",
    "model_names = [\"KNN Regressor\", \"Linear Regression\", \"Random Forest Regression\"]\n",
    "models = [knn, linear_regression, random_forest]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_score_predictor_counts(df, predictions, model):\n",
    "    # Predict Scores\n",
    "    evaluation_df = df[[\"File Name\", \"Actual Count\"]]\n",
    "    evaluation_df[\"Predicted Score\"] = model.predict(df[input_columns])\n",
    "\n",
    "    predicted_counts = []\n",
    "\n",
    "    # Get Predicted Count for Each Image\n",
    "    for idx in range(evaluation_df.shape[0]):\n",
    "        row = evaluation_df.iloc[idx]\n",
    "\n",
    "        image_name = row[\"File Name\"]\n",
    "        predicted_score = row[\"Predicted Score\"]\n",
    "\n",
    "        # Get Predicted Count for one image\n",
    "        image_count = 0\n",
    "        image_predictions = predictions[image_name]\n",
    "\n",
    "        for sub_image_predicition in image_predictions:\n",
    "            boxes, scores, labels = decode_prediction(sub_image_predicition, predicted_score, nms_threshold, use_numpy=True)\n",
    "            image_count += len(boxes)\n",
    "\n",
    "        predicted_counts.append(image_count)\n",
    "\n",
    "    evaluation_df[\"Predicted Count\"] = predicted_counts\n",
    "    absolute_difference = abs(evaluation_df[\"Actual Count\"] - evaluation_df[\"Predicted Count\"])\n",
    "\n",
    "    # Metric Calculation\n",
    "    mean_absolute_percent_error = (absolute_difference / evaluation_df[\"Actual Count\"]).mean()\n",
    "    mean_absolute_error = absolute_difference.mean()\n",
    "    error_per_ten_seals = (mean_absolute_error * 10) / evaluation_df[\"Actual Count\"].mean()\n",
    "    total_miscounted_seals = absolute_difference.sum()\n",
    "\n",
    "    return mean_absolute_percent_error, mean_absolute_error, error_per_ten_seals, total_miscounted_seals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_score_predictors(models, model_names, df, predictions):\n",
    "    data_frame_dict = {\n",
    "        \"Model Name\": [],\n",
    "        \"Mean Absolute Percent Error\": [],\n",
    "        \"Mean Absolute Error\": [],\n",
    "        \"Error per 10 Seals\": [],\n",
    "        \"Total Miscounted Seals\": [],\n",
    "    }\n",
    "    for idx in range(len(models)):\n",
    "        model = models[idx]\n",
    "        model_name = model_names[idx]\n",
    "\n",
    "        mean_absolute_percent_error, mean_absolute_error, error_per_ten_seals, total_miscounted_seals = evaluate_score_predictor_counts(df, predictions, model)\n",
    "        \n",
    "        data_frame_dict[\"Model Name\"].append(model_name)\n",
    "        data_frame_dict[\"Mean Absolute Percent Error\"].append(mean_absolute_percent_error)\n",
    "        data_frame_dict[\"Mean Absolute Error\"].append(mean_absolute_error)\n",
    "        data_frame_dict[\"Error per 10 Seals\"].append(error_per_ten_seals)\n",
    "        data_frame_dict[\"Total Miscounted Seals\"].append(total_miscounted_seals)\n",
    "\n",
    "    return pd.DataFrame(data_frame_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Mean Absolute Percent Error</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Error per 10 Seals</th>\n",
       "      <th>Total Miscounted Seals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.689395</td>\n",
       "      <td>78.58</td>\n",
       "      <td>8.262881</td>\n",
       "      <td>3929.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.720050</td>\n",
       "      <td>79.54</td>\n",
       "      <td>8.363828</td>\n",
       "      <td>3977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regression</td>\n",
       "      <td>0.633953</td>\n",
       "      <td>78.26</td>\n",
       "      <td>8.229232</td>\n",
       "      <td>3913.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Name  Mean Absolute Percent Error  Mean Absolute Error  \\\n",
       "0             KNN Regressor                     0.689395                78.58   \n",
       "1         Linear Regression                     0.720050                79.54   \n",
       "2  Random Forest Regression                     0.633953                78.26   \n",
       "\n",
       "   Error per 10 Seals  Total Miscounted Seals  \n",
       "0            8.262881                  3929.0  \n",
       "1            8.363828                  3977.0  \n",
       "2            8.229232                  3913.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results = compare_score_predictors(models, model_names, training_df, training_predictions)\n",
    "training_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Mean Absolute Percent Error</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Error per 10 Seals</th>\n",
       "      <th>Total Miscounted Seals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.669981</td>\n",
       "      <td>82.6250</td>\n",
       "      <td>7.153680</td>\n",
       "      <td>1322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.685542</td>\n",
       "      <td>83.3125</td>\n",
       "      <td>7.213203</td>\n",
       "      <td>1333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regression</td>\n",
       "      <td>0.669981</td>\n",
       "      <td>82.6250</td>\n",
       "      <td>7.153680</td>\n",
       "      <td>1322.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Name  Mean Absolute Percent Error  Mean Absolute Error  \\\n",
       "0             KNN Regressor                     0.669981              82.6250   \n",
       "1         Linear Regression                     0.685542              83.3125   \n",
       "2  Random Forest Regression                     0.669981              82.6250   \n",
       "\n",
       "   Error per 10 Seals  Total Miscounted Seals  \n",
       "0            7.153680                  1322.0  \n",
       "1            7.213203                  1333.0  \n",
       "2            7.153680                  1322.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_results = compare_score_predictors(models, model_names, validation_df, validation_predictions)\n",
    "validation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Mean Absolute Percent Error</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Error per 10 Seals</th>\n",
       "      <th>Total Miscounted Seals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.561938</td>\n",
       "      <td>18.846154</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.573502</td>\n",
       "      <td>19.230769</td>\n",
       "      <td>6.377551</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regression</td>\n",
       "      <td>0.557542</td>\n",
       "      <td>18.846154</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Name  Mean Absolute Percent Error  Mean Absolute Error  \\\n",
       "0             KNN Regressor                     0.561938            18.846154   \n",
       "1         Linear Regression                     0.573502            19.230769   \n",
       "2  Random Forest Regression                     0.557542            18.846154   \n",
       "\n",
       "   Error per 10 Seals  Total Miscounted Seals  \n",
       "0            6.250000                   245.0  \n",
       "1            6.377551                   250.0  \n",
       "2            6.250000                   245.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_results = compare_score_predictors(models, model_names, testing_df, testing_predictions)\n",
    "testing_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_latex(training_results, f\"{model_name}_score_predictor_training_ep_{epsilon_value}_nms_{nms_threshold}\")\n",
    "write_to_latex(validation_results, f\"{model_name}_score_predictor_validation_ep_{epsilon_value}_nms_{nms_threshold}\")\n",
    "write_to_latex(testing_results, f\"{model_name}_score_predictor_testing_ep_{epsilon_value}_nms_{nms_threshold}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
