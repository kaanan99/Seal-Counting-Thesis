{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from skimage import io\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.models import efficientnet_v2_m\n",
    "from torchvision import transforms\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the GPU if one exists.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using: \", device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centriod_directory = \"Centroids\"\n",
    "\n",
    "if centriod_directory not in os.listdir():\n",
    "    os.mkdir(centriod_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seal_sub_images(img_path:str, water_classifier, model, step:int, device=device) -> List:\n",
    "    \"\"\"Goes through an image and determines the center coordinates of 150x150 sub-image predicted to contain seals\n",
    "\n",
    "    Args:\n",
    "        img_path (str): path to image\n",
    "        water_classifier (Scikit learn model): water classifier\n",
    "        model (Pytorch model): CNN predicting whether a seal is present in the sub-image or not\n",
    "        step (int): distance that the boxes iterate\n",
    "        device (str, optional): Can be either 'gpu' or 'cpu'. Defaults to device.\n",
    "\n",
    "    Returns:\n",
    "        List: List of (x, y) coordinates of predicted seal sub-images\n",
    "    \"\"\"\n",
    "    # crops like reading a book\n",
    "    centroids = []\n",
    "\n",
    "    img = io.imread(img_path, plugin=\"matplotlib\")\n",
    "    \n",
    "    x_len = img.shape[1]\n",
    "    y_len = img.shape[0]\n",
    "\n",
    "    model.to(device)\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    # Iterate through y axis (Up to Down)\n",
    "    i = 0\n",
    "    while (i < y_len):\n",
    "        # If y coordinate is greater than len of image, look at the last step of image (y-coords = (ymax, ymax-step))\n",
    "        y1 = i\n",
    "        if i + step > y_len:\n",
    "            y1 = y_len-step\n",
    "            y2 = y_len\n",
    "            i = y_len\n",
    "        # Increase y coords by step\n",
    "        else:\n",
    "            y2 = i + step\n",
    "            i += step\n",
    "\n",
    "        # Iterate through x axis (left to right)\n",
    "        j = 0\n",
    "        while (j < x_len):\n",
    "            # If x coordinate is greater than len of image, look at the last step of image (x-coords = (xmax, xmax-step))\n",
    "            x1 = j\n",
    "            if j + step > x_len:\n",
    "                x1 = x_len - step\n",
    "                x2 = x_len\n",
    "                j = x_len\n",
    "            # Increase x coords by step\n",
    "            else:\n",
    "                x2 = j + step\n",
    "                j += step\n",
    "\n",
    "            # Sub images for models\n",
    "            sub_image = np.array(\n",
    "                    img[y1:y2, x1:x2]\n",
    "                )\n",
    "            sub_image_water_classifier = np.array(\n",
    "                    [\n",
    "                    np.array([sub_image]) # Wrapping in another array\n",
    "                    .reshape(22500, 3)\n",
    "                    .mean(axis=0)\n",
    "                    ]\n",
    "                )\n",
    "            \n",
    "            # Model predictions\n",
    "            water_prediction = water_classifier.predict(sub_image_water_classifier)\n",
    "            if water_prediction < .5:\n",
    "                # Get subimage for CNN\n",
    "                sub_image_cnn = (\n",
    "                    transform(sub_image)\n",
    "                    .unsqueeze(0)\n",
    "                    .to(device)\n",
    "                    )\n",
    "                \n",
    "                # Get seal prediction\n",
    "                seal_prediction = np.argmax(\n",
    "                    model(sub_image_cnn)\n",
    "                        .cpu()\n",
    "                        .detach()\n",
    "                        .numpy(), \n",
    "                    axis = 1\n",
    "                )[0]\n",
    "\n",
    "                if seal_prediction > .5:\n",
    "\n",
    "                    x_center = (x1 + x2) / 2\n",
    "                    y_center = (y1 + y2) / 2\n",
    "                    centroids.append((x_center, y_center))\n",
    "                    \n",
    "    return centroids\n",
    "\n",
    "\n",
    "def get_file_names(path:str) -> List[str]:\n",
    "    \"\"\"Get name of all image files located at the specified path\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to directory containing image files\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of all image file names\n",
    "    \"\"\"\n",
    "    names = set()\n",
    "    for x in os.listdir(path):\n",
    "        names.add(x.split(\".\")[0])\n",
    "    return list(names)\n",
    "\n",
    "\n",
    "def get_predicted_sub_images(cnn, water_classifier, path:str, write_path:str=None, version:str=\"\") -> Dict:\n",
    "    \"\"\"For each image file in the specified directory, predictions location of seals and returns centriods of sub-images\n",
    "\n",
    "    Args:\n",
    "        cnn (Pytorch model): CNN model to predict is seals are within the sub-image\n",
    "        water_classifier (Scikit learn model): Water classifier to discard majority water images\n",
    "        path (str): Path to directory containing image files\n",
    "        write_path (str, optional): Path to location where centriods should be stored. Defaults to None.\n",
    "        version (str, optional): Additional label for centriod file. Defaults to \"\".\n",
    "\n",
    "    Returns:\n",
    "        Dict: _description_\n",
    "    \"\"\"\n",
    "    seal_centroids = {}\n",
    "\n",
    "    file_names = get_file_names(path)\n",
    "\n",
    "    # Get Centriods\n",
    "    for file_name in tqdm(file_names, desc = \"Determining Images with Seals\"):\n",
    "        img_name =  f\"{file_name}.JPG\"\n",
    "        centroids = get_seal_sub_images(path+img_name, water_classifier, cnn, 150)\n",
    "        seal_centroids[file_name] = centroids\n",
    "\n",
    "    # Save file\n",
    "    if write_path != None:\n",
    "        with open(write_path + f\"/seals_centroids_{version}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(seal_centroids, f)\n",
    "            \n",
    "    return seal_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CNN\n",
    "efficientnet = efficientnet_v2_m()\n",
    "efficientnet.classifier[1] = nn.Linear(in_features=1280, out_features=2)\n",
    "efficientnet.load_state_dict(torch.load(\"../../../seal_detector\\Models\\PyTorch\\ImageClassifierPytorch9\"))\n",
    "efficientnet.eval()\n",
    "efficientnet = efficientnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load water classifier\n",
    "f = open(\"../../../seal_detector\\Models\\water_classifier\\water_classifier\", \"rb\")\n",
    "water_classifier = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Paths to images\n",
    "training_path = \"../../../Training, Val, and Test Images/Training Images/\"\n",
    "validation_path = \"../../../Training, Val, and Test Images/Validation Images/\"\n",
    "testing_path = \"../../../Training, Val, and Test Images/Test Images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = \"Centroids\"\n",
    "\n",
    "\n",
    "centroids_training = get_predicted_sub_images(efficientnet, water_classifier, training_path, write_path=write_path, version=\"training\")\n",
    "centroids_validation = get_predicted_sub_images(efficientnet, water_classifier, validation_path, write_path=write_path, version=\"validation\")\n",
    "centroids_testing= get_predicted_sub_images(efficientnet, water_classifier, testing_path, write_path=write_path, version=\"testing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
