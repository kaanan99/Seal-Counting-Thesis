{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import ops\n",
    "import os\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights, fasterrcnn_resnet50_fpn_v2\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Splitting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(xml):\n",
    "  label = xml.find_all(\"name\")\n",
    "  xmin = xml.find_all(\"xmin\")\n",
    "  ymin = xml.find_all(\"ymin\")\n",
    "  xmax = xml.find_all(\"xmax\")\n",
    "  ymax = xml.find_all(\"ymax\")\n",
    "  min_size = min(len(label), len(xmin), len(ymin), len(xmax), len(ymax))\n",
    "  for i in range(min_size):\n",
    "      label[i] = label[i].text\n",
    "      xmin[i] = xmin[i].text\n",
    "      ymin[i] = ymin[i].text\n",
    "      xmax[i] = xmax[i].text\n",
    "      ymax[i] = ymax[i].text\n",
    "  df = pd.DataFrame({\"label\": label[:min_size], \"xmin\": xmin[:min_size], \"ymin\": ymin[:min_size], \"xmax\": xmax[:min_size], \"ymax\": ymax[:min_size]})\n",
    "  return df\n",
    "\n",
    "def clean_up_data(df):\n",
    "   df = df[df[\"label\"] != \"Label Studio\"]\n",
    "#    cat1 = 'adult male'\n",
    "#    cat2 = 'male juvenile / female juvenile / adult female'\n",
    "#    cat3 = 'pup'\n",
    "\n",
    "#    cat1_diffs = [\"Adult Male\", \"Adult male\", \"adult male seal\", \"Seal\"]\n",
    "\n",
    "#    cat2_diffs = ['juvenile male / juvenile female / adult female',\n",
    "#                  'male juvenile / female juvenile /adult female',\n",
    "#                  'Adult Female or Young Male',\n",
    "#                  'male juvenile/female juvenile/adult female',\n",
    "#                  'Juvenile male / juvenile female / adult female',\n",
    "#                  'Juvenile male/ juvenile female/ adult female',\n",
    "#                  'male juvenile / female juvenile / adulf female',\n",
    "#                  'adult female seal', '\\\\\\\\', ']', '\\'']\n",
    "#    cat3_diffs = ['Pup', 'Juvenile', 'baby seal', 'juvenile seal']\n",
    "#    for cat1_diff in cat1_diffs:\n",
    "#        df.loc[df[\"label\"] == cat1_diff, ['label']] = cat1\n",
    "#    for cat2_diff in cat2_diffs:\n",
    "#        df.loc[df[\"label\"] == cat2_diff, ['label']] = cat2\n",
    "#    for cat3_diff in cat3_diffs:\n",
    "#        df.loc[df[\"label\"] == cat3_diff, ['label']] = cat3\n",
    "   return df\n",
    "\n",
    "def get_bb(in_path, xml):\n",
    "   df = pd.DataFrame()\n",
    "   i = 0\n",
    "   for x in xml:\n",
    "      f = open(in_path + x)\n",
    "      xml_file = bs(\"\".join(f.readlines()), features=\"xml\")\n",
    "      df_temp = parse_xml(xml_file)\n",
    "      df_temp.insert(0, \"file_num\", str(i).zfill(4))\n",
    "      df = pd.concat([df, df_temp])\n",
    "      f.close()\n",
    "      i+=1\n",
    "   df = clean_up_data(df)\n",
    "   return df\n",
    "\n",
    "def find_bounding_boxes(df_img, x_size, y_size, xmin, ymin, xmax, ymax):\n",
    "  col_names = list(df_img.columns)\n",
    "  col_names.append(\"percent_seal\")\n",
    "  df_bb = pd.DataFrame()\n",
    "  for row in df_img.itertuples():\n",
    "    bb_xmin = int(row[3])\n",
    "    bb_ymin = int(row[4])\n",
    "    bb_xmax = int(row[5])\n",
    "    bb_ymax = int(row[6])\n",
    "\n",
    "    bb_xmin_ = max(bb_xmin - xmin, 0)\n",
    "    bb_ymin_ = max(bb_ymin - ymin, 0)\n",
    "    bb_xmax_ = min(bb_xmax - xmin, xmax - xmin)\n",
    "    bb_ymax_ = min(bb_ymax - ymin, ymax - ymin)\n",
    "    bb_row = [row[1], row[2], bb_xmin_, bb_ymin_, bb_xmax_, bb_ymax_]\n",
    "\n",
    "    # if a bounding box was found\n",
    "    if ((bb_xmin_ >= 0 and bb_xmin_ <= x_size) and\n",
    "       (bb_ymin_ >= 0 and bb_ymin_ <= y_size) and\n",
    "       (bb_xmax_ >= 0 and bb_xmax_ <= x_size) and\n",
    "       (bb_ymax_ >= 0 and bb_ymax_ <= y_size)):\n",
    "      height = bb_ymax_ - bb_ymin_; length = bb_xmax_ - bb_xmin_\n",
    "      area = height * length # area of bb in image\n",
    "      bb_area = (bb_xmax - bb_xmin) * (bb_ymax - bb_ymin) # total area of bb\n",
    "\n",
    "      if (bb_area == 0): # ignore bounding boxes that don't have any area\n",
    "        break\n",
    "\n",
    "      percent_seal_present = area/bb_area # % of bb present in subimage\n",
    "      # print(\"original bb coordinates:\", row)\n",
    "      # print(\"subimage coordinates:\", [xmin, ymin, xmax, ymax])\n",
    "      # print(\"new bb coordinates:\", bb_row)\n",
    "      # print(percent_seal_present, area, bb_area)\n",
    "      bb_row.append(percent_seal_present)\n",
    "      df_bb = pd.concat([df_bb,pd.Series(bb_row, index=col_names).to_frame().T])\n",
    "\n",
    "  if len(df_bb) == 0:\n",
    "    df_bb = None\n",
    "  return df_bb\n",
    "\n",
    "def split_image(img, df_img, x_size, y_size, x_int, y_int, thresh):\n",
    "    # _size is the length in each direction\n",
    "    # _int is the interval you shift right or down by\n",
    "    # ex. (150, 150, 75, 75) - each split creates a 150x150 images and shifts over by 75 pixels each run through.\n",
    "    x_len = img.shape[1]\n",
    "    y_len = img.shape[0]\n",
    "\n",
    "    seal_count = []\n",
    "    sub_images = []\n",
    "    # crops like reading a book\n",
    "    i = 0\n",
    "    while (i < y_len):\n",
    "        # updates the new y coordinates\n",
    "        y1 = i\n",
    "        if i + y_size > y_len:\n",
    "            y1 = y_len-y_size\n",
    "            y2 = y_len\n",
    "            i = y_len\n",
    "        else:\n",
    "            y2 = i + y_size\n",
    "            i += y_int\n",
    "\n",
    "        j = 0\n",
    "        while (j < x_len):\n",
    "            # updates the new x coordinates\n",
    "            x1 = j\n",
    "            if j + x_size > x_len:\n",
    "                x1 = x_len - x_size\n",
    "                x2 = x_len\n",
    "                j = x_len\n",
    "            else:\n",
    "                x2 = j + x_size\n",
    "                j += x_int\n",
    "            df_bb = find_bounding_boxes(df_img, x_size, y_size, x1, y1, x2, y2)\n",
    "            if df_bb is not None and df_bb[\"percent_seal\"].max() > thresh:\n",
    "                seal_count.append(df_bb.shape[0])\n",
    "                cropped = img[y1:y2,x1:x2]\n",
    "                sub_images.append(cropped)\n",
    "    return sub_images, seal_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_detection_model(version, num_classes = 2, feature_extraction = True):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "        num_classes: int\n",
    "            Number of classes to predict. Must include the \n",
    "            background which is class 0 by definition!\n",
    "        feature_extraction: bool\n",
    "            Flag indicating whether to freeze the pre-trained \n",
    "            weights. If set to True the pre-trained weights will be  \n",
    "            frozen and not be updated during.\n",
    "    Returns\n",
    "        model: FasterRCNN\n",
    "    \"\"\"\n",
    "    if version == 2:\n",
    "        model = fasterrcnn_resnet50_fpn_v2(weights='DEFAULT')\n",
    "    elif version == 1:\n",
    "        model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1)    \n",
    "    # If True, the pre-trained weights will be frozen.\n",
    "    if feature_extraction == True:\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False    \n",
    "    # Replace the original 91 class top layer with a new layer\n",
    "    # tailored for num_classes.\n",
    "    in_feats = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_feats, num_classes)    \n",
    "    return model\n",
    "\n",
    "def predict(model, image, device=\"cpu\", transform = transforms.Compose([transforms.ToTensor()])):\n",
    "    image = transform(np.array(image)).unsqueeze(0).type(torch.FloatTensor).to(device)\n",
    "    pred = model(image)\n",
    "    return pred\n",
    "\n",
    "def detach_pred(pred):\n",
    "    pred[\"boxes\"] = pred[\"boxes\"].detach().cpu()\n",
    "    pred[\"scores\"] = pred[\"scores\"].detach().cpu()\n",
    "    pred[\"labels\"] = pred[\"labels\"].detach().cpu()\n",
    "    return pred\n",
    "\n",
    "def decode_prediction(prediction, \n",
    "                      score_threshold = 0.8, \n",
    "                      nms_iou_threshold = 0.2):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "        prediction: dict\n",
    "        score_threshold: float\n",
    "        nms_iou_threshold: float\n",
    "    Returns\n",
    "        prediction: tuple\n",
    "    \"\"\"\n",
    "    boxes = prediction[\"boxes\"]\n",
    "    scores = prediction[\"scores\"]\n",
    "    labels = prediction[\"labels\"]    \n",
    "    # Remove any low-score predictions.\n",
    "    if score_threshold is not None:\n",
    "        want = scores > score_threshold\n",
    "        boxes = boxes[want]\n",
    "        scores = scores[want]\n",
    "        labels = labels[want]    \n",
    "    # Remove any overlapping bounding boxes using NMS.\n",
    "    if nms_iou_threshold is not None:\n",
    "        want = torchvision.ops.nms(boxes = boxes, scores = scores, iou_threshold = nms_iou_threshold)\n",
    "        boxes = boxes[want]\n",
    "        scores = scores[want]\n",
    "        labels = labels[want]    \n",
    "        return boxes.detach().cpu().numpy()\n",
    "    \n",
    "def nms_boxes(pred, thresh):\n",
    "    boxes = pred[\"boxes\"]\n",
    "    scores = pred[\"scores\"]\n",
    "    labels = pred[\"labels\"]\n",
    "    want = torchvision.ops.nms(boxes = boxes, scores = scores, iou_threshold = thresh)\n",
    "    boxes = boxes[want]\n",
    "    scores = scores[want]\n",
    "    labels = labels[want]    \n",
    "    return len(boxes.detach().cpu().numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frame Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(file_name, model, path, device=\"cpu\"):\n",
    "    img_name = file_name + \".JPG\"\n",
    "    xml_name = file_name + \".xml\"\n",
    "    image = io.imread(path + img_name, plugin=\"matplotlib\")\n",
    "    xml = get_bb(path, [xml_name])\n",
    "    sub_images, seal_count = split_image(image, xml, 150, 150, 75, 75, .3)\n",
    "    preds = []\n",
    "    for s in sub_images:\n",
    "        pred = detach_pred(predict(model, s, device)[0])\n",
    "        preds.append(pred)\n",
    "    return preds, seal_count\n",
    "\n",
    "def get_file_names(path):\n",
    "    return set([x.split(\".\")[0] for x in os.listdir(path)])\n",
    "\n",
    "def get_preds_counts(path, model, device):\n",
    "    preds_counts = {}\n",
    "    file_names = get_file_names(path)\n",
    "    for file_name in tqdm(file_names):\n",
    "        preds_counts[file_name] = get_preds(file_name, model, path, device)\n",
    "    return preds_counts\n",
    "\n",
    "def gen_pred_data(d, thresh):\n",
    "    file_names = []\n",
    "    actual_count = []\n",
    "    best_scores = []\n",
    "    pred_count = []\n",
    "    boxes_total = []\n",
    "    boxes_iou = []\n",
    "    potential_scores = np.arange(0, 1, .05)\n",
    "    for file_name in tqdm(d.keys()):\n",
    "        preds, counts = d[file_name]\n",
    "        for i in range(len(preds)):\n",
    "            pred = preds[i]\n",
    "            best_score = 0\n",
    "            best_error = math.inf\n",
    "            best_count = 0\n",
    "            for ps in potential_scores:\n",
    "                boxes = decode_prediction(pred, ps, thresh)\n",
    "                error = abs(len(boxes) - counts[i])\n",
    "                if error < best_error:\n",
    "                    best_error = error\n",
    "                    best_score = ps\n",
    "                    best_count = len(boxes)\n",
    "            file_names.append(file_name)\n",
    "            actual_count.append(counts[i])\n",
    "            best_scores.append(best_score)\n",
    "            pred_count.append(best_count)\n",
    "            boxes_total.append(len(pred[\"boxes\"]))\n",
    "            boxes_iou.append(nms_boxes(pred, thresh))\n",
    "    return pd.DataFrame({\"File Name\": file_names, \"Actual Count\": actual_count, \"Best Score\": best_scores, \"Best Count\": pred_count, \"Total Boxes\": boxes_total, \"Boxes IOU\": boxes_iou})\n",
    "\n",
    "def gen_pred_data_eval(d, thresh):\n",
    "    file_names = []\n",
    "    boxes_total = []\n",
    "    boxes_iou = []\n",
    "    index = []\n",
    "    for file_name in tqdm(d.keys()):\n",
    "        preds = d[file_name]\n",
    "        i = 0\n",
    "        for i in range(len(preds)):\n",
    "            pred = preds[i]\n",
    "            file_names.append(file_name)\n",
    "            boxes_total.append(len(pred[\"boxes\"]))\n",
    "            boxes_iou.append(nms_boxes(pred, thresh))\n",
    "            index.append(i)\n",
    "            i += 1\n",
    "    return pd.DataFrame({\"File Name\": file_names,  \"Total Boxes\": boxes_total, \"Boxes IOU\": boxes_iou, \"Index\": index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_path = r\"C:\\Users\\kaanan\\Desktop\\Training, Val, and Test Images\\Training Images/\"\n",
    "validation_image_path = r\"C:\\Users\\kaanan\\Desktop\\Training, Val, and Test Images\\Validation Images/\"\n",
    "model_path = r\"C:\\Users\\kaanan\\Desktop\\RCNN\\RCNN Evaluation Information\\Trial 2\\Models\\rcnn_trial2_50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Connect to the GPU if one exists.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using: \", device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_object_detection_model(2)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "transform=transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Training Data\n",
      "Found Validation Data\n"
     ]
    }
   ],
   "source": [
    "thresh =.05\n",
    "\n",
    "files = os.listdir(r\"C:\\Users\\kaanan\\Desktop\\RCNN\\Data/\")\n",
    "if \"individual_best_scores_train.csv\" in files:\n",
    "    print(\"Found Training Data\")\n",
    "    train_preds = pd.read_csv(r\"C:\\Users\\kaanan\\Desktop\\RCNN\\Data/individual_best_scores_train.csv\")\n",
    "else:\n",
    "    print(\"Training Data not found. Generating new.\")\n",
    "    pred_counts_train = get_preds_counts(training_image_path, model, device)\n",
    "    train_preds = gen_pred_data(pred_counts_train, thresh)\n",
    "    print(\"Training Data generated, writing for future use\")\n",
    "    train_preds.to_csv(r\"C:\\Users\\kaanan\\Desktop\\RCNN\\Data/individual_best_scores_train.csv\")\n",
    "\n",
    "if \"individual_best_scores_val.csv\" in files:\n",
    "    print(\"Found Validation Data\")\n",
    "    val_preds =  pd.read_csv(r\"C:\\Users\\kaanan\\Desktop\\RCNN\\Data/individual_best_scores_val.csv\")\n",
    "else:\n",
    "    print(\"Validation Data not found, generating new.\")\n",
    "    pred_counts_val = get_preds_counts(validation_image_path, model, device)\n",
    "    val_preds = gen_pred_data(pred_counts_val, thresh)\n",
    "    print(\"Validation Data generated, saving for future use.\")\n",
    "    val_preds.to_csv(r\"C:\\Users\\kaanan\\Desktop\\RCNN\\Data/individual_best_scores_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv(\"../Data/training_min_0.05_300_V2\")\n",
    "df_validation = pd.read_csv(\"../Data/validation_min_0.05_300_V2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds[\"Box Left Ratio\"] =  train_preds[\"Boxes IOU\"] / train_preds[\"Total Boxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds[\"Box Left Ratio\"] =  val_preds[\"Boxes IOU\"] / val_preds[\"Total Boxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = df_training.drop(columns = [\"File Name\", \"Score\", \"Actual Count\", \"Unnamed: 0\"])\n",
    "image_x_no_rgb = df_training[[\"Box Num\", \"Cluster Num\", \"Biggest Cluster\", \"Smallest Cluster\"]]\n",
    "image_y = df_training[\"Score\"]\n",
    "rf_rgb = RandomForestRegressor(max_samples = .45, random_state=0).fit(image_x, image_y)\n",
    "rf_no_rgb = RandomForestRegressor(max_samples = .7, random_state=0).fit(image_x_no_rgb, image_y)\n",
    "df_training[\"Image Score RGB\"] = rf_rgb.predict(image_x)\n",
    "df_training[\"Image Score\"] = rf_no_rgb.predict(image_x_no_rgb)\n",
    "df_training[\"Image Count\"] = df_training[\"Actual Count\"]\n",
    "df_training = df_training.drop(columns=[\"Unnamed: 0\", \"Actual Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = df_validation.drop(columns = [\"File Name\", \"Score\", \"Actual Count\", \"Unnamed: 0\"])\n",
    "image_x_no_rgb = df_validation[[\"Box Num\", \"Cluster Num\", \"Biggest Cluster\", \"Smallest Cluster\"]]\n",
    "image_y = df_validation[\"Score\"]\n",
    "df_validation[\"Image Score RGB\"] = rf_rgb.predict(image_x)\n",
    "df_validation[\"Image Score\"] = rf_no_rgb.predict(image_x_no_rgb)\n",
    "df_validation[\"Image Count\"] = df_validation[\"Actual Count\"]\n",
    "df_validation = df_validation.drop(columns=[\"Unnamed: 0\", \"Actual Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_training = df_training.merge(train_preds, on= \"File Name\")\n",
    "combined_validation = df_validation.merge(val_preds, on= \"File Name\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaanan\\AppData\\Local\\Temp\\ipykernel_12748\\1299928806.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train[\"Box Left Ratio\"] = x_train['Box Left Ratio'].fillna(0)\n",
      "C:\\Users\\kaanan\\AppData\\Local\\Temp\\ipykernel_12748\\1299928806.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_val[\"Box Left Ratio\"] = x_val['Box Left Ratio'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "x_train = combined_training[['Box Num', 'Cluster Num', 'Biggest Cluster','Smallest Cluster', 'Biggest R', 'Biggest G', 'Biggest B', 'Smallest R','Smallest B', 'Smallest G', 'Average R', 'Average B', 'Average G','Image Score RGB','Total Boxes', 'Boxes IOU','Box Left Ratio']]\n",
    "y_train = combined_training[\"Best Score\"]\n",
    "x_val = combined_validation[['Box Num', 'Cluster Num', 'Biggest Cluster','Smallest Cluster', 'Biggest R', 'Biggest G', 'Biggest B', 'Smallest R','Smallest B', 'Smallest G', 'Average R', 'Average B', 'Average G','Image Score RGB','Total Boxes', 'Boxes IOU','Box Left Ratio']]\n",
    "y_val = combined_validation[\"Best Score\"]\n",
    "x_train[\"Box Left Ratio\"] = x_train['Box Left Ratio'].fillna(0)\n",
    "x_val[\"Box Left Ratio\"] = x_val['Box Left Ratio'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056853692506134694"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_score_rgb = RandomForestRegressor(random_state=0).fit(x_train, y_train)\n",
    "pred_scores = rf_score_rgb.predict(x_train)\n",
    "abs(pred_scores-y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13755912826265604"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_scores = rf_score_rgb.predict(x_val)\n",
    "abs(pred_scores-y_val).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaanan\\AppData\\Local\\Temp\\ipykernel_12748\\1452543124.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train[\"Box Left Ratio\"] = x_train['Box Left Ratio'].fillna(0)\n",
      "C:\\Users\\kaanan\\AppData\\Local\\Temp\\ipykernel_12748\\1452543124.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_val[\"Box Left Ratio\"] = x_val['Box Left Ratio'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "x_train = combined_training[['Box Num', 'Cluster Num', 'Biggest Cluster','Smallest Cluster', \"Image Score\", 'Total Boxes', 'Boxes IOU','Box Left Ratio']]\n",
    "y_train = combined_training[\"Best Score\"]\n",
    "x_val = combined_validation[['Box Num', 'Cluster Num', 'Biggest Cluster','Smallest Cluster', \"Image Score\", 'Total Boxes', 'Boxes IOU','Box Left Ratio']]\n",
    "y_val = combined_validation[\"Best Score\"]\n",
    "x_train[\"Box Left Ratio\"] = x_train['Box Left Ratio'].fillna(0)\n",
    "x_val[\"Box Left Ratio\"] = x_val['Box Left Ratio'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05730548465634972"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_score_no_rgb = RandomForestRegressor(random_state=0).fit(x_train, y_train)\n",
    "pred_scores = rf_score_no_rgb.predict(x_train)\n",
    "abs(pred_scores-y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13771415026046066"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_scores = rf_score_no_rgb.predict(x_val)\n",
    "abs(pred_scores-y_val).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Count of Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\kaanan\\Desktop\\RCNN\\MetaData\\training_preds_total_V2\", \"rb\") as f:\n",
    "    actual_training_preds = pickle.load(f)\n",
    "with open(r\"C:\\Users\\kaanan\\Desktop\\RCNN\\MetaData\\validation_preds_total_V2\", \"rb\") as f:\n",
    "    actual_val_preds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007147789001464844,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 50,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbdeece7efe44d59c67914213b68b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005239725112915039,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 16,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed259608f1e43ba92d65e66d742b828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_eval = gen_pred_data_eval(actual_training_preds, thresh)\n",
    "val_eval = gen_pred_data_eval(actual_val_preds, thresh)\n",
    "train_eval[\"Box Left Ratio\"] =  train_eval[\"Boxes IOU\"] / train_eval[\"Total Boxes\"]\n",
    "val_eval[\"Box Left Ratio\"] =  val_eval[\"Boxes IOU\"] / val_eval[\"Total Boxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_training_eval = df_training.merge(train_eval, on= \"File Name\")\n",
    "combined_validation_eval = df_validation.merge(val_eval, on= \"File Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaanan\\AppData\\Local\\Temp\\ipykernel_12748\\1153485420.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train[\"Box Left Ratio\"] = x_train['Box Left Ratio'].fillna(0)\n",
      "C:\\Users\\kaanan\\AppData\\Local\\Temp\\ipykernel_12748\\1153485420.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_val[\"Box Left Ratio\"] = x_val['Box Left Ratio'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "x_train = combined_training_eval[['Box Num', 'Cluster Num', 'Biggest Cluster','Smallest Cluster', \"Image Score\", 'Total Boxes', 'Boxes IOU','Box Left Ratio']]\n",
    "x_val = combined_validation_eval[['Box Num', 'Cluster Num', 'Biggest Cluster','Smallest Cluster', \"Image Score\", 'Total Boxes', 'Boxes IOU','Box Left Ratio']]\n",
    "x_train[\"Box Left Ratio\"] = x_train['Box Left Ratio'].fillna(0)\n",
    "x_val[\"Box Left Ratio\"] = x_val['Box Left Ratio'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_training_eval[\"Predicted Score\"] = rf_score_no_rgb.predict(x_train)\n",
    "combined_validation_eval[\"Predicted Score\"] = rf_score_no_rgb.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_counts_training = combined_training_eval[[\"File Name\", \"Image Count\"]].drop_duplicates()\n",
    "actual_counts_validation = combined_validation_eval[[\"File Name\", \"Image Count\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_image_counts(df, preds, thresh):\n",
    "    counts = []\n",
    "    for i in range(df.shape[0]):\n",
    "        row = df.iloc[i, :]\n",
    "        file_name = row[\"File Name\"]\n",
    "        index = row[\"Index\"]\n",
    "        pred_score = row[\"Predicted Score\"]\n",
    "        counts.append(len(decode_prediction(preds[file_name][index], pred_score, thresh)))\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_training_eval[\"Pred Counts\"] = get_sub_image_counts(combined_training_eval, actual_training_preds, thresh)\n",
    "combined_validation_eval[\"Pred Counts\"] = get_sub_image_counts(combined_validation_eval, actual_val_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7085822683527391"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_counts = combined_training_eval.groupby(\"File Name\").sum().reset_index()[[\"File Name\", \"Pred Counts\"]].merge(actual_counts_training, on=\"File Name\")\n",
    "training_counts[\"Count Diff\"] = abs(training_counts[\"Pred Counts\"] - training_counts[\"Image Count\"])\n",
    "training_counts[\"Percent Diff\"] = (training_counts[\"Count Diff\"] / training_counts[\"Image Count\"]).fillna(0)\n",
    "training_counts[\"Percent Diff\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8786181077296269"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_counts = combined_validation_eval.groupby(\"File Name\").sum().reset_index()[[\"File Name\", \"Pred Counts\"]].merge(actual_counts_validation, on=\"File Name\")\n",
    "val_counts[\"Count Diff\"] = abs(val_counts[\"Pred Counts\"] - val_counts[\"Image Count\"])\n",
    "val_counts[\"Percent Diff\"] = (val_counts[\"Count Diff\"] / val_counts[\"Image Count\"]).fillna(0)\n",
    "val_counts[\"Percent Diff\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
