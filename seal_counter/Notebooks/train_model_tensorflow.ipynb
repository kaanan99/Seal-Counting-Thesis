{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3LU5nxRitaH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from cnn_utils import get_labels_and_sub_images, get_labels, display_result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNYN35yai2g0"
   },
   "outputs": [],
   "source": [
    "# Load Model\n",
    "resnet = ResNet50V2(\n",
    "    include_top=False, \n",
    "    weights='imagenet', \n",
    "    input_shape=(150, 150, 3), \n",
    "    pooling='max', \n",
    "    classes=2\n",
    ")\n",
    "\n",
    "# Freeze layers\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ResNet Model\n",
    "resnet_model = Sequential()\n",
    "resnet_model.add(resnet)\n",
    "resnet_model.add(Flatten())\n",
    "\n",
    "# Add additional layers\n",
    "additional_layers_nodes = [1024, 512, 256, 128, 64, 32, 16]\n",
    "for node_amount in additional_layers_nodes:\n",
    "    resnet_model.add(\n",
    "        Dense(node_amount, activation=\"relu\")\n",
    "    )\n",
    "\n",
    "# Add final node \n",
    "resnet_model.add(\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_path = \"../Data\"\n",
    "\n",
    "train_img_data = np.load(f\"{data_path}/train_images.npy\", allow_pickle=True)\n",
    "train_bb_data = np.load(f\"{data_path}/train_bb_data.npy\", allow_pickle=True)\n",
    "\n",
    "val_img_data  = np.load(f\"{data_path}/val_images.npy\", allow_pickle=True)\n",
    "val_bb_data = np.load(f\"{data_path}/val_bb_data.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47eo3m-_oZ_A"
   },
   "outputs": [],
   "source": [
    "seal_threshold = .3\n",
    "\n",
    "# Separate the images and image data between seal and no seal\n",
    "label_1_img, label_1, label_0_img, label_0 = get_labels_and_sub_images(train_img_data, train_bb_data, threshold=seal_threshold)\n",
    "\n",
    "# Get the labels for the validation data\n",
    "val_label = get_labels(val_bb_data, seal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfomed_images = []\n",
    "transformed_labels = []\n",
    "\n",
    "#Add mirror images and horizontal flip\n",
    "for sub_image in label_1_img:\n",
    "    \n",
    "    # Apply tranformations\n",
    "    mirrored_image = np.fliplr(sub_image)\n",
    "    horizontal_flipped_image = np.flipud(sub_image)\n",
    "\n",
    "    # Add new data\n",
    "    transfomed_images.append(mirrored_image)\n",
    "    transfomed_images.append(horizontal_flipped_image)\n",
    "\n",
    "    transformed_labels.append(1)\n",
    "    transformed_labels.append(1)\n",
    "\n",
    "# Combine images\n",
    "label_1_img += transfomed_images\n",
    "label_1 += transformed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_labels = np.array(label_1 + label_0)\n",
    "total_images = np.array(label_1_img + label_0_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = np.unique(total_labels)\n",
    "weights = class_weight.compute_class_weight(\n",
    "    \"balanced\", \n",
    "    classes=unique_classes, \n",
    "    y=total_labels\n",
    ")\n",
    "class_weights = {0:weights[0], 1:weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "resnet_model.compile(\n",
    "    optimizer=Adam(learning_rate=3e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "resnet_model.fit(\n",
    "    total_images, \n",
    "    total_labels, \n",
    "    verbose= 1, \n",
    "    epochs = 10, \n",
    "    batch_size=150, \n",
    "    shuffle=True, \n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Predictions for validation set\n",
    "validation_raw_predictions = (\n",
    "    resnet_model\n",
    "    .predict(val_img_data)\n",
    "    .flatten()\n",
    ")\n",
    "\n",
    "# Convert probalities of a sub-image containing a seal into labels\n",
    "validation_label_predictions = [1 if pred > .5 else 0 for pred in validation_raw_predictions]\n",
    "\n",
    "# Display Evaluation Metrics\n",
    "display_result_metrics(val_label, validation_label_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Test\"\n",
    "resnet_model.save(f\"../Models/Tensorflow/{model_name}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
